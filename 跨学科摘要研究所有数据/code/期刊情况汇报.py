import os
import numpy as np

def count_words(text):
    # ç®€å•åˆ†è¯è®¡æ•°
    return len(text.split())

def analyze_corpus(folder_path):
    word_counts = []
    filenames = []

    for filename in os.listdir(folder_path):
        if filename.endswith(".txt"):
            file_path = os.path.join(folder_path, filename)
            with open(file_path, 'r', encoding='utf-8') as f:
                text = f.read()
                count = count_words(text)
                word_counts.append(count)
                filenames.append(filename)

    num_files = len(word_counts)
    total_words = sum(word_counts)
    min_words = np.min(word_counts)
    max_words = np.max(word_counts)
    mean_words = np.mean(word_counts)
    std_words = np.std(word_counts)

    print(f"ğŸ“ è¯­æ–™è·¯å¾„ï¼š{folder_path}")
    print(f"ğŸ“„ æ‘˜è¦æ€»æ•°ï¼š{num_files}")
    print(f"ğŸ”¢ æ€»è¯æ•°ï¼š{total_words}")
    print(f"ğŸ“‰ æœ€çŸ­æ‘˜è¦ï¼š{min_words} è¯")
    print(f"ğŸ“ˆ æœ€é•¿æ‘˜è¦ï¼š{max_words} è¯")
    print(f"ğŸ“Š å¹³å‡é•¿åº¦ï¼š{mean_words:.2f} è¯")
    print(f"ğŸ“ æ ‡å‡†å·®ï¼š{std_words:.2f} è¯")
    print("-" * 50)

# =================== æ‰§è¡Œ ===================

# è¯­è¨€å­¦
al_path = "/Users/fafaya/Research-on-AI-generated-text-series/Abstracts_All_AL/AL_Abstracts_All"
analyze_corpus(al_path)

# è®¡ç®—æœº
cs_path = "/Users/fafaya/Research-on-AI-generated-text-series/Abstracts_All_CS/CS_Abstracts_All"
analyze_corpus(cs_path)
