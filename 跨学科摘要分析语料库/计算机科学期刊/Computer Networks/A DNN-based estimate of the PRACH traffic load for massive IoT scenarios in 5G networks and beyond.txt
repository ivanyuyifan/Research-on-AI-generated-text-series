The massive Internet of Things (IoT) scenario refers to a huge number of Machine Type Communications (MTC) characterized by sporadic transmissions of small-sized packets. In order to manage the uplink radio resource allocation in cellular networks, several access schemes have been proposed. These schemes are mainly based on a grant-based Random Access (RA) procedure and proper load-aware access controls, e.g., Access Class Barring (ACB) techniques, dynamic uplink radio resource allocation, and so on. The development of an efficient approach to estimate the traffic load is extremely important for the proper functioning of these access schemes. With the ever-increasing number of transmitting MTC devices, expected with Beyond 5G (B5G) and 6G networks, additional challenges to obtain a correct real-time traffic load estimation are posed. Deep learning techniques, in this context, offer learning ability and optimization capability to properly support this scenario. In this paper, we propose a current access attempts estimation, based on Deep Neural Network (DNN), which accepts as input only the information really available at the next generation Node B (gNB). The network was trained and tested with a dataset properly created and composed by more than 21 million points. The DNN-based traffic load estimation method is then compared with other benchmark schemes available in the literature, in terms of regression accuracy, both in a static analysis, which considers a stand-alone RA cycle, and through a long-term analysis with a time-varying offered load. The latter analysis was performed both by adopting a theoretical arrival process proposed by 3GPP, and by using traces of real traffic data.